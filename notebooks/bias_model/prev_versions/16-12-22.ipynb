{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification\n",
    "\n",
    "MAX_SEQUENCE_LENGTH = 128\n",
    "LEARNING_RATE = 1e-5\n",
    "BATCH_SIZE = 32\n",
    "NUM_EPOCHS = 3  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "def tokenize(sentences, max_length=MAX_SEQUENCE_LENGTH, padding='max_length'):\n",
    "    # Using the tokenizer from the DistilBert model from HuggingFace\n",
    "    return tokenizer(\n",
    "        sentences,\n",
    "        truncation=True,\n",
    "        padding=padding,\n",
    "        max_length=max_length,\n",
    "        return_tensors=\"tf\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv('../toy_model/media_bias.csv')\n",
    "\n",
    "# Clean dataset\n",
    "df = df[df.Label_bias != 'No agreement']\n",
    "df = df[df.article != 'NaN']\n",
    "df = df[df.sentence != 'NaN']\n",
    "\n",
    "# Replace label with 0, 1\n",
    "df['Label_bias'] = df['Label_bias'].replace('Biased', 1)\n",
    "df['Label_bias'] = df['Label_bias'].replace('Non-biased', 0)\n",
    "\n",
    "df = df.rename(columns={'sentence': 'text', 'Label_bias': 'label'})\n",
    "\n",
    "train_data, validation_data, train_label, validation_label = train_test_split(\n",
    "    df['text'].tolist(),\n",
    "    df['label'].tolist(),\n",
    "    test_size=.15,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    dict(tokenize(train_data)),  # Convert BatchEncoding instance to dictionary\n",
    "    train_label\n",
    ")).shuffle(1000).batch(BATCH_SIZE).prefetch(1)\n",
    "validation_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    dict(tokenize(validation_data)),\n",
    "    validation_label\n",
    ")).batch(BATCH_SIZE).prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_projector.weight', 'vocab_layer_norm.weight', 'vocab_projector.bias', 'vocab_transform.weight', 'vocab_layer_norm.bias', 'vocab_transform.bias']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.bias', 'pre_classifier.weight', 'classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'DistilBertForSequenceClassification' object has no attribute 'compile'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [7], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[39m# add learning layers to model\u001b[39;00m\n\u001b[0;32m      7\u001b[0m optimizer \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39moptimizers\u001b[39m.\u001b[39mAdam(learning_rate\u001b[39m=\u001b[39mLEARNING_RATE)\n\u001b[1;32m----> 8\u001b[0m model\u001b[39m.\u001b[39;49mcompile(\n\u001b[0;32m      9\u001b[0m     optimizer\u001b[39m=\u001b[39moptimizer,\n\u001b[0;32m     10\u001b[0m     loss\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mlosses\u001b[39m.\u001b[39mSparseCategoricalCrossentropy(from_logits\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m),\n\u001b[0;32m     11\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\verni\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1265\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1263\u001b[0m     \u001b[39mif\u001b[39;00m name \u001b[39min\u001b[39;00m modules:\n\u001b[0;32m   1264\u001b[0m         \u001b[39mreturn\u001b[39;00m modules[name]\n\u001b[1;32m-> 1265\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m object has no attribute \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m   1266\u001b[0m     \u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, name))\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DistilBertForSequenceClassification' object has no attribute 'compile'"
     ]
    }
   ],
   "source": [
    "model = DistilBertForSequenceClassification.from_pretrained(\n",
    "    'distilbert-base-uncased',\n",
    "    num_labels=2\n",
    ")\n",
    "# add learning layers to model\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE)\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.fit(\n",
    "    x=train_dataset,\n",
    "    validation_data=validation_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=NUM_EPOCHS,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 81s 5s/step - loss: 0.7294\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7293604016304016"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test model and plot confusion matrix\n",
    "model.evaluate(validation_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get predictions\n",
    "predictions = model.predict(validation_dataset)\n",
    "predictions = tf.nn.softmax(predictions[0], axis=1)\n",
    "predictions = tf.argmax(predictions, axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[1 1 0 0 0 0 1 1 1 0 1 0 0 1 0 0 0 1 1 0 1 0 1 0 0 0 0 0 1 0 1 0 0 0 1 1 0\n",
      " 0 1 1 0 0 1 1 0 1 0 1 0 0 1 1 1 1 1 0 1 0 1 1 1 0 1 0 1 0 1 0 1 0 0 0 0 1\n",
      " 0 0 1 1 0 0 0 0 0 1 0 1 0 1 1 1 1 1 1 1 0 1 0 1 1 1 0 0 0 0 1 0 1 1 0 0 0\n",
      " 1 0 1 0 1 1 1 1 0 0 0 1 1 0 0 1 1 1 1 1 1 1 1 1 1 0 0 0 1 0 1 1 1 1 1 1 0\n",
      " 0 1 0 1 0 0 1 1 1 1 1 1 0 0 0 1 1 0 1 0 1 0 0 0 1 1 0 1 0 0 0 1 1 0 0 0 0\n",
      " 1 0 0 0 1 1 1 0 1 1 0 0 0 1 1 1 1 0 1 0 1 1 1 1 0 0 1 1 0 1 1 0 0 0 1 0 0\n",
      " 1 0 0 1 1 0 0 0 1 1 1], shape=(233,), dtype=int64)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x700 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "def plot_confusion_matrix(y_true, y_pred):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    sns.heatmap(cm, annot=True, fmt='d')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Truth')\n",
    "    plt.show()\n",
    "\n",
    "plot_confusion_matrix(validation_label, predictions)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7381974248927039\n"
     ]
    }
   ],
   "source": [
    "# show accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(validation_label, predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = dict(tokenizer([\"This is a factual sentence that can be seen in a good light don't you think so, but it seems like they're all unbiased.\",\"YouTube is making clear there will be no “birtherism” on its platform during this year’s U.S. presidential election – a belated response to a type of conspiracy theory more prevalent in the 2012 race.\", \"The increasingly bitter dispute between American women’s national soccer team and the U.S. Soccer Federation spilled onto the field Wednesday night when players wore their warm-up jerseys inside outin a protest before their 3-1 victory over Japan.\",\"A professor who teaches climate change classes — a subject some would question as a legitimate area of study — said she has seen students who suffer fear, grief, stress, and anxiety about the future.\"], padding=True, truncation=True, return_tensors=\"tf\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': <tf.Tensor: shape=(4, 50), dtype=int32, numpy=\n",
      "array([[  101,  2023,  2003,  1037, 25854,  6251,  2008,  2064,  2022,\n",
      "         2464,  1999,  1037,  2204,  2422,  2123,  1005,  1056,  2017,\n",
      "         2228,  2061,  1010,  2021,  2009,  3849,  2066,  2027,  1005,\n",
      "         2128,  2035,  4895, 11607,  6924,  1012,   102,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0],\n",
      "       [  101,  7858,  2003,  2437,  3154,  2045,  2097,  2022,  2053,\n",
      "         1523,  4182, 11124,  6491,  1524,  2006,  2049,  4132,  2076,\n",
      "         2023,  2095,  1521,  1055,  1057,  1012,  1055,  1012,  4883,\n",
      "         2602,  1516,  1037, 20252,  3064,  3433,  2000,  1037,  2828,\n",
      "         1997,  9714,  3399,  2062, 15157,  1999,  1996,  2262,  2679,\n",
      "         1012,   102,     0,     0,     0],\n",
      "       [  101,  1996,  6233,  8618,  7593,  2090,  2137,  2308,  1521,\n",
      "         1055,  2120,  4715,  2136,  1998,  1996,  1057,  1012,  1055,\n",
      "         1012,  4715,  4657, 13439,  3031,  1996,  2492,  9317,  2305,\n",
      "         2043,  2867,  5078,  2037,  4010,  1011,  2039, 28772,  2503,\n",
      "         2041,  2378,  1037,  6186,  2077,  2037,  1017,  1011,  1015,\n",
      "         3377,  2058,  2900,  1012,   102],\n",
      "       [  101,  1037,  2934,  2040, 12011,  4785,  2689,  4280,  1517,\n",
      "         1037,  3395,  2070,  2052,  3160,  2004,  1037, 11476,  2181,\n",
      "         1997,  2817,  1517,  2056,  2016,  2038,  2464,  2493,  2040,\n",
      "         9015,  3571,  1010,  9940,  1010,  6911,  1010,  1998, 10089,\n",
      "         2055,  1996,  2925,  1012,   102,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0]])>, 'attention_mask': <tf.Tensor: shape=(4, 50), dtype=int32, numpy=\n",
      "array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0],\n",
      "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 0, 0, 0],\n",
      "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1],\n",
      "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0]])>}\n"
     ]
    }
   ],
   "source": [
    "print(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TFSequenceClassifierOutput(loss=None, logits=array([[-1.4891721,  1.2353058],\n",
      "       [-2.3630428,  2.0507863],\n",
      "       [ 2.066503 , -2.1085992],\n",
      "       [ 2.0238175, -2.0706954]], dtype=float32), hidden_states=None, attentions=None)\n",
      "[[0.06154434 0.93845564]\n",
      " [0.01196386 0.98803616]\n",
      " [0.98485917 0.01514085]\n",
      " [0.9836092  0.01639073]]\n",
      "[1 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "newPrediction = model.predict(inputs)\n",
    "print(newPrediction)\n",
    "#get the highest probability and its index from the prediction\n",
    "newPrediction = tf.nn.softmax(newPrediction[0], axis=1).numpy()\n",
    "print(newPrediction)\n",
    "label = tf.argmax(newPrediction, axis=1).numpy()\n",
    "# print the index with the highest probability from tensor\n",
    "print(label)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the model to a local folder\n",
    "model.save_pretrained('./model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at ./model were not used when initializing TFDistilBertForSequenceClassification: ['dropout_79']\n",
      "- This IS expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some layers of TFDistilBertForSequenceClassification were not initialized from the model checkpoint at ./model and are newly initialized: ['dropout_99']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load the model from the local folder for testing purposes\n",
    "modelOpen = TFDistilBertForSequenceClassification.from_pretrained(\"./model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TFSequenceClassifierOutput(loss=None, logits=array([[-1.4891721,  1.2353058],\n",
      "       [-2.3630428,  2.0507863],\n",
      "       [ 2.066503 , -2.1085992],\n",
      "       [ 2.0238175, -2.0706954]], dtype=float32), hidden_states=None, attentions=None)\n",
      "[[0.06154434 0.93845564]\n",
      " [0.01196386 0.98803616]\n",
      " [0.98485917 0.01514085]\n",
      " [0.9836092  0.01639073]]\n",
      "[1 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "#Testing if the loaded model works\n",
    "newPrediction = modelOpen.predict(inputs)\n",
    "newPrediction = tf.nn.softmax(newPrediction[0], axis=1).numpy()\n",
    "print(newPrediction)\n",
    "label = tf.argmax(newPrediction, axis=1).numpy()\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.dropout.Dropout object at 0x000001D938D01D20>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.dropout.Dropout object at 0x000001D8B79A5300>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.dropout.Dropout object at 0x000001D8B94F63E0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.dropout.Dropout object at 0x000001D8BAD18CD0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.dropout.Dropout object at 0x000001D8BAD18DC0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.dropout.Dropout object at 0x000001D8BAD8CC10>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as embeddings_layer_call_fn, embeddings_layer_call_and_return_conditional_losses, transformer_layer_call_fn, transformer_layer_call_and_return_conditional_losses, LayerNorm_layer_call_fn while saving (showing 5 of 164). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./modelpb\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./modelpb\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save('./modelpb', save_format='tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'logits': array([[-1.4891721,  1.2353058],\n",
      "       [-2.3630428,  2.0507863],\n",
      "       [ 2.066503 , -2.1085992],\n",
      "       [ 2.0238175, -2.0706954]], dtype=float32)}\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# Load the model from the local folder for testing purposes\n",
    "modelOpen = tf.keras.models.load_model('./bert_model_15-12-22')\n",
    "\n",
    "import numpy as np\n",
    "#Testing if the loaded model works\n",
    "newPrediction = modelOpen.predict(inputs)\n",
    "predictionArray = np.argmax(newPrediction, axis=1)\n",
    "print(newPrediction)\n",
    "print(predictionArray)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'logits': array([[-1.4891721,  1.2353058],\n",
      "       [-2.3630428,  2.0507863],\n",
      "       [ 2.066503 , -2.1085992],\n",
      "       [ 2.0238175, -2.0706954]], dtype=float32)}\n",
      "[[0.00827894 0.12624098]\n",
      " [0.00345507 0.28533763]\n",
      " [0.28985763 0.00445616]\n",
      " [0.27774528 0.00462831]]\n",
      "[1 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "from scipy.special import softmax\n",
    "print(newPrediction)\n",
    "confidence = softmax(newPrediction['logits'])\n",
    "print(confidence)\n",
    "predictionArray = np.argmax(newPrediction['logits'], axis=1)\n",
    "print(predictionArray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b2abd1138ce1c26e3850e921765871411c611b4978bcd07656c7e4d1d85e9831"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
