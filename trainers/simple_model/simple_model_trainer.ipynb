{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tempfile\n",
    "# For N-dimensional array manipulation\n",
    "import numpy as np\n",
    "# Plotting library\n",
    "import matplotlib.pyplot as plt\n",
    "# For data analysis and data structures in DataFrames\n",
    "import pandas as pd\n",
    "# For data visualization\n",
    "import seaborn as sns\n",
    "\n",
    "# For machine learning algorithms and evaluation metrics\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "#import tensorflow\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "# import TextVectorization from keras\n",
    "from keras.layers import TextVectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv('../../dataset/media_bias.csv')\n",
    "\n",
    "# Clean dataset\n",
    "df = df[df.Label_bias != 'No agreement']\n",
    "df = df[df.article != 'NaN']\n",
    "df = df[df.sentence != 'NaN']\n",
    "\n",
    "# Replace label with 0, 1\n",
    "df['Label_bias'] = df['Label_bias'].replace('Biased', 1)\n",
    "df['Label_bias'] = df['Label_bias'].replace('Non-biased', 0)\n",
    "\n",
    "# Only use sentence column and bias column\n",
    "df = df[['sentence', 'Label_bias']]\n",
    "df = df.rename(columns={'sentence': 'text', 'Label_bias': 'label'})\n",
    "\n",
    "# Split data into X and y\n",
    "X = df['text']\n",
    "y = df['label']\n",
    "\n",
    "# Remove numbers from all strings in X\n",
    "X = X.str.replace('\\d+', '', regex=True)\n",
    "\n",
    "# Remove punctuation from all strings in X\n",
    "X = X.str.replace('[^\\w\\s]','',regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape:  (992,)\n",
      "X_test shape:  (311,)\n",
      "X_train shape:  (992,)\n",
      "X_test shape:  (311,)\n"
     ]
    }
   ],
   "source": [
    "# Split data into train, validation and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# Print shape of train, validation and test\n",
    "print(\"X_train shape: \", X_train.shape)\n",
    "# print(\"X_val shape: \", X_val.shape)\n",
    "print(\"X_test shape: \", X_test.shape)\n",
    "\n",
    "\n",
    "# Flatten X_train for training and X_test for testing\n",
    "X_train = np.array(X_train).flatten()\n",
    "X_test = np.array(X_test).flatten()\n",
    "    \n",
    "# X_train = X_train.to_numpy()\n",
    "# X_train = np.array(X_train).flatten()\n",
    "# print x shape\n",
    "print(\"X_train shape: \", X_train.shape)\n",
    "# print test shape\n",
    "print(\"X_test shape: \", X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-25 14:50:24.613899: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2022-12-25 14:50:24.613940: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ArchYA): /proc/driver/nvidia/version does not exist\n",
      "2022-12-25 14:50:24.615619: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " text_vectorization (TextVec  (None, 128)              0         \n",
      " torization)                                                     \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 128, 128)          126976    \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 128, 256)         263168    \n",
      " l)                                                              \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 32768)             0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 32768)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               4194432   \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,592,897\n",
      "Trainable params: 4,592,897\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/4\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/home/younis/.virtualenvs/AiProject/lib/python3.10/site-packages/keras/engine/training.py\", line 1021, in train_function  *\n        return step_function(self, iterator)\n    File \"/home/younis/.virtualenvs/AiProject/lib/python3.10/site-packages/keras/engine/training.py\", line 1010, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/younis/.virtualenvs/AiProject/lib/python3.10/site-packages/keras/engine/training.py\", line 1000, in run_step  **\n        outputs = model.train_step(data)\n    File \"/home/younis/.virtualenvs/AiProject/lib/python3.10/site-packages/keras/engine/training.py\", line 860, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/home/younis/.virtualenvs/AiProject/lib/python3.10/site-packages/keras/engine/training.py\", line 918, in compute_loss\n        return self.compiled_loss(\n    File \"/home/younis/.virtualenvs/AiProject/lib/python3.10/site-packages/keras/engine/compile_utils.py\", line 184, in __call__\n        self.build(y_pred)\n    File \"/home/younis/.virtualenvs/AiProject/lib/python3.10/site-packages/keras/engine/compile_utils.py\", line 133, in build\n        self._losses = tf.nest.map_structure(self._get_loss_object, self._losses)\n    File \"/home/younis/.virtualenvs/AiProject/lib/python3.10/site-packages/keras/engine/compile_utils.py\", line 272, in _get_loss_object\n        loss = losses_mod.get(loss)\n    File \"/home/younis/.virtualenvs/AiProject/lib/python3.10/site-packages/keras/losses.py\", line 2369, in get\n        return deserialize(identifier)\n    File \"/home/younis/.virtualenvs/AiProject/lib/python3.10/site-packages/keras/losses.py\", line 2324, in deserialize\n        return deserialize_keras_object(\n    File \"/home/younis/.virtualenvs/AiProject/lib/python3.10/site-packages/keras/utils/generic_utils.py\", line 709, in deserialize_keras_object\n        raise ValueError(\n\n    ValueError: Unknown loss function: sparese_catageorical_crossentropy. Please ensure this object is passed to the `custom_objects` argument. See https://www.tensorflow.org/guide/keras/save_and_serialize#registering_the_custom_object for details.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [5], line 20\u001b[0m\n\u001b[1;32m     17\u001b[0m model\u001b[39m.\u001b[39msummary()\n\u001b[1;32m     19\u001b[0m \u001b[39m# Train model\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(X_train, y_train, epochs\u001b[39m=\u001b[39;49m\u001b[39m4\u001b[39;49m, batch_size\u001b[39m=\u001b[39;49m\u001b[39m16\u001b[39;49m, validation_data\u001b[39m=\u001b[39;49m(X_val, y_val))\n",
      "File \u001b[0;32m~/.virtualenvs/AiProject/lib/python3.10/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     68\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.virtualenvs/AiProject/lib/python3.10/site-packages/tensorflow/python/framework/func_graph.py:1147\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func.<locals>.autograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m   1146\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m\"\u001b[39m\u001b[39mag_error_metadata\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m-> 1147\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mag_error_metadata\u001b[39m.\u001b[39mto_exception(e)\n\u001b[1;32m   1148\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1149\u001b[0m     \u001b[39mraise\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/home/younis/.virtualenvs/AiProject/lib/python3.10/site-packages/keras/engine/training.py\", line 1021, in train_function  *\n        return step_function(self, iterator)\n    File \"/home/younis/.virtualenvs/AiProject/lib/python3.10/site-packages/keras/engine/training.py\", line 1010, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/younis/.virtualenvs/AiProject/lib/python3.10/site-packages/keras/engine/training.py\", line 1000, in run_step  **\n        outputs = model.train_step(data)\n    File \"/home/younis/.virtualenvs/AiProject/lib/python3.10/site-packages/keras/engine/training.py\", line 860, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/home/younis/.virtualenvs/AiProject/lib/python3.10/site-packages/keras/engine/training.py\", line 918, in compute_loss\n        return self.compiled_loss(\n    File \"/home/younis/.virtualenvs/AiProject/lib/python3.10/site-packages/keras/engine/compile_utils.py\", line 184, in __call__\n        self.build(y_pred)\n    File \"/home/younis/.virtualenvs/AiProject/lib/python3.10/site-packages/keras/engine/compile_utils.py\", line 133, in build\n        self._losses = tf.nest.map_structure(self._get_loss_object, self._losses)\n    File \"/home/younis/.virtualenvs/AiProject/lib/python3.10/site-packages/keras/engine/compile_utils.py\", line 272, in _get_loss_object\n        loss = losses_mod.get(loss)\n    File \"/home/younis/.virtualenvs/AiProject/lib/python3.10/site-packages/keras/losses.py\", line 2369, in get\n        return deserialize(identifier)\n    File \"/home/younis/.virtualenvs/AiProject/lib/python3.10/site-packages/keras/losses.py\", line 2324, in deserialize\n        return deserialize_keras_object(\n    File \"/home/younis/.virtualenvs/AiProject/lib/python3.10/site-packages/keras/utils/generic_utils.py\", line 709, in deserialize_keras_object\n        raise ValueError(\n\n    ValueError: Unknown loss function: sparese_catageorical_crossentropy. Please ensure this object is passed to the `custom_objects` argument. See https://www.tensorflow.org/guide/keras/save_and_serialize#registering_the_custom_object for details.\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape[0])\n",
    "# Create DNN using tensorflow\n",
    "vectorize_layer = TextVectorization(max_tokens=512, output_mode='int', output_sequence_length=128)\n",
    "vectorize_layer.adapt(X_train)\n",
    "model = keras.Sequential([\n",
    "    vectorize_layer,\n",
    "    layers.Embedding(input_dim=X_train.shape[0] , output_dim=128, mask_zero=True),\n",
    "    layers.Bidirectional(layers.LSTM(128, return_sequences=True)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dropout(0.4),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "model.compile(loss='sparese_catageorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "# Train model\n",
    "history = model.fit(X_train, y_train, epochs=4, batch_size=16, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 2s 191ms/step - loss: 1.0383 - accuracy: 0.6367\n",
      "Loss:  1.0383291244506836\n",
      "Accuracy:  0.6366559267044067\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "[[0.1754145 ]\n",
      " [0.00295903]] 1 is bias, 0 is non-bias\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# model.save('model/saved_model')\n",
    "# Evaluate model\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(\"Loss: \", loss)\n",
    "print(\"Accuracy: \", accuracy)\n",
    "\n",
    "prediction = model.predict([\"YouTube is making clear there will be no “birtherism” on its platform during this year’s U.S. presidential election – a belated response to a type of conspiracy theory more prevalent in the 2012 race.\", \"The increasingly bitter dispute between American women’s national soccer team and the U.S. Soccer Federation spilled onto the field Wednesday night when players wore their warm-up jerseys inside outin a protest before their 3-1 victory over Japan.\"])\n",
    "print(prediction, \"1 is bias, 0 is non-bias\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./model/1/\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Found untraced functions such as lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model/1/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model/1/assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f9b08d277c0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f9b059c6c20> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    }
   ],
   "source": [
    "parent_dir = os.path.split(os.getcwd())[0] + \"\\\\\" + os.path.split(os.getcwd())[1]\n",
    "save_path = parent_dir + \"/model/1/\"\n",
    "# tf.saved_model.save(model, save_path) - DOESN'T SAVE THE LAYERS\n",
    "\n",
    "model.save(save_path, save_format='tf') # ERROR states layers aren't saved, but keras_metadata.pb is saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def _serving_input_receiver_fn():\n",
    "#     serialized_tf_example = tf.placeholder(dtype=tf.string, shape=None, \n",
    "#                                            name='input_example_tensor')\n",
    "#     # key (e.g. 'examples') should be same with the inputKey when you \n",
    "#     # buid the request for prediction\n",
    "#     receiver_tensors = {'examples': serialized_tf_example}\n",
    "#     inputs = {'text': tf.placeholder(tf.string, [None])}\n",
    "#     return tf.estimator.export.ServingInputReceiver(inputs, receiver_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Buckets:\n",
      "example_bucket_v1\n",
      "example_bucket_v2-aiproject-dit825\n",
      "Listed all storage buckets.\n",
      "Models:\n",
      "Listed all models.\n"
     ]
    }
   ],
   "source": [
    "from google.cloud import aiplatform\n",
    "from google.cloud import storage\n",
    "import os\n",
    "project_id = 'dit825'\n",
    "os.environ[\"GOOGLE_CLOUD_PROJECT\"] = project_id\n",
    "storage_client = storage.Client(project=project_id)\n",
    "buckets = storage_client.list_buckets()\n",
    "print(\"Buckets:\")\n",
    "for bucket in buckets:\n",
    "    print(bucket.name) \n",
    "print(\"Listed all storage buckets.\")\n",
    "# List all models in the project from aiplatform\n",
    "aiplatform.init(project=project_id, location='europe-west4')\n",
    "models = aiplatform.Model.list()\n",
    "print(\"Models:\")\n",
    "for model in models:\n",
    "    print(model)\n",
    "print(\"Listed all models.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "vectorizer.fit(X_train)\n",
    "\n",
    "train = vectorizer.transform(X_train)\n",
    "test  = vectorizer.transform(X_test)\n",
    "\n",
    "classifier = LogisticRegression()\n",
    "classifier.fit(train, y_train)\n",
    "score = classifier.score(test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7106109324758842\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-project",
   "language": "python",
   "name": "aiproject"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b2abd1138ce1c26e3850e921765871411c611b4978bcd07656c7e4d1d85e9831"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
